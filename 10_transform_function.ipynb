{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def taxi_trips_transformations(taxi_trips : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Perform transformations with taxi data\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    taxi trips: pd.Dataframe\n",
    "        the DataFrame holding the daily taxi trips\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: transfomerd Dataframe holding the daily taxi trips\n",
    "    \"\"\"\n",
    "    if not isinstance(taxi_trips, pd.DataFrame):\n",
    "        raise TypeError(\"taxi_trips is not a valid pandas DataFrame\")\n",
    "\n",
    "    taxi_trips.drop([\"pickup_census_tract\", \"dropoff_census_tract\", \"pickup_centroid_location\", \"dropoff_centroid_location\"], axis=1, inplace=True)\n",
    "\n",
    "    taxi_trips.dropna(inplace= True)\n",
    "\n",
    "    taxi_trips.rename(columns={\"pickup_community_area\" : \"pickup_community_area_id\"\n",
    "                           , \"dropoff_community_area\" : \"dropoff_community_area_id\"}, inplace=True)\n",
    "    taxi_trips[\"trip_start_timestamp\"] = pd.to_datetime(taxi_trips[\"trip_start_timestamp\"])\n",
    "    taxi_trips[\"datetime_for_weather\"] = taxi_trips[\"trip_start_timestamp\"].dt.floor(\"H\")   \n",
    "\n",
    "    return taxi_trips\n",
    "    \n",
    "def update_taxi_trips_with_master_data(taxi_trips : pd.DataFrame, payment_type_master : pd.DataFrame , company_master : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        taxi_trips (pd.DataFrame): Dataframe with the daily taxi trips \n",
    "        payment_type_master (pd.DataFrame): The paymnent type master table\n",
    "        company_master (pd.DataFrame): The company master table\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The taxi trips data with only payment_type_id, and company_id, without company or paymnet type values\n",
    "    \"\"\"\n",
    "    taxi_trips_id = taxi_trips.merge(payment_type_master, on = \"payment_type\")\n",
    "    taxi_trips_id = taxi_trips_id.merge(company_master, on = \"company\")\n",
    "    taxi_trips_id.drop([\"payment_type\" , \"company\"], axis= 1 , inplace= True)\n",
    "    return taxi_trips_id    \n",
    "\n",
    "def updated_master(taxi_trips : pd.DataFrame, master : pd.DataFrame , id_column : str, value_column : str) -> pd.DataFrame:\n",
    "    \"\"\"Extend the  master with new values if there are any paramaters\n",
    "\n",
    "    Args:updated_company_master\n",
    "        taxi_trips (pd.DataFrame): Dataframe holding the daily taxi_trips\n",
    "        company_master (pd.DataFrame): Dataframe holding the master data\n",
    "        id_column : str The id column of the master Dataframe \n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated master data, if new values are in the taxi data, they will be loaded to it. \n",
    "    \"\"\"\n",
    "    max_id = master[id_column].max()\n",
    "    new_values_list = [value for value in taxi_trips[value_column].values if value not in master[value_column].values]\n",
    "    new_values_df = pd.DataFrame({\n",
    "        id_column : range (max_id +1 , max_id + len(new_values_list)+1),\n",
    "        value_column : new_values_list\n",
    "    })\n",
    "\n",
    "    updated_master = pd.concat([master , new_values_df], ignore_index= True)\n",
    "    return updated_master\n",
    "\n",
    "def transform_weather_data(wheater_data: json) -> pd.DataFrame:\n",
    "    \"\"\"Make transformations on the daily weather api response\n",
    "\n",
    "    Args:\n",
    "        wheater_data (json): The daily weather data from the Open Meteo API \n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame representation of the data\n",
    "    \"\"\"\n",
    "    wheater_data_filtered = {\n",
    "        \"datetime\" : wheater_data[\"hourly\"][\"time\"],\n",
    "        \"temperature\" : wheater_data[\"hourly\"][\"temperature_2m\"],\n",
    "        \"windspeed\" : wheater_data[\"hourly\"][\"wind_speed_10m\"],\n",
    "        \"rain\" : wheater_data[\"hourly\"][\"rain\"],\n",
    "        \"precipitation\" : wheater_data[\"hourly\"][\"precipitation\"]\n",
    "    }\n",
    "    weather_df = pd.DataFrame(wheater_data_filtered)\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"datetime\"])\n",
    "    #wheater_data.to_csv(\"04_wheater_data_date.csv\", index = False)\n",
    "    return weather_df\n",
    "    \n",
    "def read_csv_from_s3(bucket : str, path: str, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Downloads csv file from an S3 bucket\n",
    "\n",
    "    bucket : str\n",
    "        The bucket wehere the files at\n",
    "    path : str\n",
    "        The folders to the file\n",
    "    filename : str\n",
    "        Name of the file\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of the downlaoded file\n",
    "    \"\"\"\n",
    "    \n",
    "    s3 = boto3.client(\"s3\")\n",
    "    full_path = f\"{path}{filename}\"\n",
    "    \n",
    "    object = s3.get_object(Bucket = bucket, Key = full_path)\n",
    "    object = object[\"Body\"].read().decode(\"utf-8\") \n",
    "    output_df = pd.read_csv(StringIO(object))\n",
    "    \n",
    "    return output_df\n",
    "def upload_dataframe_to_s3(dataframe : pd.DataFrame , bucket : str , path : str):\n",
    "    \n",
    "    s3 = boto3.client(\"s3\")\n",
    "    buffer = StringIO()\n",
    "    dataframe.to_csv(buffer, index=False)\n",
    "    df_content = buffer.getvalue()\n",
    "    s3.put_object(Bucket=bucket, Key=path, Body=df_content)\n",
    "    \n",
    "    \n",
    "def upload_master_to_s3(bucket: str, path: str, file_type: str, dataframe: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Uploads the master data payment type or company to S3\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "    bucket : str\n",
    "    path : str\n",
    "    file_type : str\n",
    "    dataframe : dataframe\n",
    "    \"\"\"\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    master_file_path = f\"{path}{file_type}_master.csv\"\n",
    "    previous_master_file_path = f\"transfomerd_data/master_table_previous_version/{file_type}_master_previous_version.csv\"\n",
    "\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket,\n",
    "        CopySource={\"Bucket\": bucket, \"Key\": master_file_path},\n",
    "        Key=previous_master_file_path\n",
    "    )\n",
    "\n",
    "    #buffer = StringIO()\n",
    "    #dataframe.to_csv(buffer, index=False)\n",
    "    #df_content = buffer.getvalue()\n",
    "    #s3.put_object(Bucket=bucket, Key=master_file_path, Body=df_content)\n",
    "    \n",
    "    upload_dataframe_to_s3(bucket = bucket , dataframe = dataframe , path = master_file_path )\n",
    "    \n",
    "def upload_and_move_file_on_s3(dataframe: pd.DataFrame , datetime_col : str, bucket :str, target_path_transformed: str , \n",
    "file_type :str, source_path :str, target_path_raw : str, filename: str):\n",
    "    \n",
    "    s3 = boto3.client(\"s3\")\n",
    "    formatted_date = dataframe[datetime_col].iloc[0].strftime(\"%Y-%m-%d\")\n",
    "    new_path_with_filename = f\"{target_path_transformed}{file_type}_{formatted_date}.csv\"\n",
    "    upload_dataframe_to_s3(bucket = bucket, dataframe = dataframe, path = new_path_with_filename)\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket,\n",
    "        CopySource={\"Bucket\": bucket, \"Key\": f\"{source_path}{filename}\"},\n",
    "        Key=f\"{target_path_raw}{filename}\"\n",
    "    )\n",
    "    \n",
    "    s3.delete_object(Bucket=bucket, Key=f\"{source_path}{filename}\")\n",
    "    \n",
    "#MAIN FUNCTION\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    bucket = \"cubixdatachicagobm\"\n",
    "    raw_weather_folder = \"raw_data/to_processed/weather_data/\"\n",
    "    raw_taxi_trips_folder = \"raw_data/to_processed/taxi_data/\"\n",
    "    target_taxi_trips_folder =\"raw_data/processed/taxi_data/\"\n",
    "    target_weather_folder =\"raw_data/processed/weather_data/\"\n",
    "    \n",
    "\n",
    "    transfomerd_taxi_trips_folder = \"transformed_data/taxi_trips/\"\n",
    "    transfomerd_weather_folder = \"transformed_data/weather/\"\n",
    "    \n",
    "    payment_type_master_folder = \"transformed_data/payment_type /\"\n",
    "    company_master_folder = \"transformed_data/company /\"\n",
    "    \n",
    "    payment_type_master_file_name = \"payment_type_master.csv\"\n",
    "    company_master_file_name = \"company_master.csv\"\n",
    "    \n",
    "    payment_type_master = read_csv_from_s3 (bucket = bucket, path = payment_type_master_folder, filename = payment_type_master_file_name)\n",
    "    company_master = read_csv_from_s3 (bucket = bucket, path = company_master_folder, filename = company_master_file_name)\n",
    "    \n",
    "    # TAXI DATA TRANSFORMATION AND LOADING\n",
    "    \n",
    "    for file in s3.list_objects(Bucket = bucket , Prefix = raw_taxi_trips_folder )['Contents']:\n",
    "        taxi_trip_key = file[\"Key\"]\n",
    "        \n",
    "        if taxi_trip_key.split(\"/\")[-1].strip() != \"\":\n",
    "            if taxi_trip_key.split(\".\")[1] == \"json\":\n",
    "                \n",
    "               filename = taxi_trip_key.split(\"/\")[-1]\n",
    "               \n",
    "               response = s3.get_object(Bucket = bucket, Key = taxi_trip_key)\n",
    "               content = response[\"Body\"]\n",
    "               taxi_trips_data_json = json.loads(content.read())\n",
    "               \n",
    "               taxi_trips_data_raw = pd.DataFrame(taxi_trips_data_json)\n",
    "               taxi_trips_transformed = taxi_trips_transformations(taxi_trips_data_raw)\n",
    "             \n",
    "               company_master_update = updated_master(taxi_trips_transformed, company_master , \"company_id\" , \"company\")\n",
    "               payment_type_master_updated = updated_master(taxi_trips_transformed , payment_type_master , \"payment_type_id\" , \"payment_type\")\n",
    "               \n",
    "               taxi_trips = update_taxi_trips_with_master_data(taxi_trips_transformed, payment_type_master_updated , company_master_update)\n",
    "               \n",
    "               upload_and_move_file_on_s3(\n",
    "                   dataframe = taxi_trips,\n",
    "                   datetime_col = \"datetime_for_weather\",\n",
    "                   bucket = bucket,\n",
    "                   file_type = \"taxi\",\n",
    "                   filename = filename,\n",
    "                   source_path = raw_taxi_trips_folder,\n",
    "                   target_path_raw = target_taxi_trips_folder,\n",
    "                   target_path_transformed = transfomerd_taxi_trips_folder\n",
    "                   )\n",
    "                       \n",
    "               print(\"taxi_trips moved and uploaded\")\n",
    "               \n",
    "               \n",
    "               upload_master_to_s3(bucket = bucket, path = payment_type_master_folder, file_type = \"payment_type\" , dataframe = payment_type_master_updated)\n",
    "               print(\"payment_type_master has been updated!\")\n",
    "               \n",
    "               upload_master_to_s3(bucket = bucket, path = company_master_folder, file_type = \"company\" , dataframe = company_master_update)\n",
    "               print(\"payment_type_master has been updated!\")\n",
    "               \n",
    "    #WEATHER DATA TRANSFORMATION AND LOADING\n",
    "    \n",
    "    for file in s3.list_objects(Bucket = bucket , Prefix = raw_weather_folder )['Contents']:\n",
    "        weather_key = file[\"Key\"]\n",
    "        \n",
    "        if weather_key.split(\"/\")[-1].strip() != \"\":\n",
    "            if weather_key.split(\".\")[1] == \"json\":\n",
    "                \n",
    "                filename = weather_key.split(\"/\")[-1]\n",
    "            \n",
    "                response = s3.get_object(Bucket = bucket, Key = weather_key)\n",
    "                content = response[\"Body\"]\n",
    "                weather_data_json = json.loads(content.read())\n",
    "                weather_data = transform_weather_data(weather_data_json)\n",
    "                \n",
    "                upload_and_move_file_on_s3(\n",
    "                   dataframe = weather_data,\n",
    "                   datetime_col = \"datetime\",\n",
    "                   bucket = bucket,\n",
    "                   file_type = \"weather\",\n",
    "                   filename = filename,\n",
    "                   source_path = raw_weather_folder,\n",
    "                   target_path_raw = target_weather_folder,\n",
    "                   target_path_transformed = transfomerd_weather_folder\n",
    "                   )\n",
    "                   \n",
    "                print(\"weather is uploaded and moved\")\n",
    "               \n",
    "               \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
